{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aILdGac_h5g7",
    "outputId": "44865571-a7fe-4acf-851b-1cfc66ccb1d5"
   },
   "outputs": [],
   "source": [
    "!pip uninstall Cython -y # Temporary fix for \"No module named 'object_detection'\" error\n",
    "\n",
    "!git clone --depth 1 https://github.com/tensorflow/models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!protoc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!which protoc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd /kaggle/working/models/research\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!protoc --proto_path=models/research/ \\\n",
    "models/research/object_detection/protos/*.proto \\\n",
    "--python_out=models/research/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KtffhtgClTqs"
   },
   "outputs": [],
   "source": [
    "# Modify setup.py file to install the tf-models-official repository targeted at TF v2.8.0\n",
    "\n",
    "import re\n",
    "\n",
    "with open('/kaggle/working/models/research/object_detection/packages/tf2/setup.py') as f:\n",
    "\n",
    "    s = f.read()\n",
    "\n",
    "\n",
    "\n",
    "with open('/kaggle/working/models/research/setup.py', 'w') as f:\n",
    "\n",
    "    # Set fine_tune_checkpoint path\n",
    "\n",
    "    s = re.sub('tf-models-official>=2.5.1',\n",
    "\n",
    "               'tf-models-official==2.8.0', s)\n",
    "\n",
    "    f.write(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jAMWNI5elZYE",
    "outputId": "5b592ac4-6350-4451-8e66-03b3469128ed"
   },
   "outputs": [],
   "source": [
    "# Install the Object Detection API (NOTE: This block takes about 10 minutes to finish executing)\n",
    "\n",
    "\n",
    "\n",
    "# Need to do a temporary fix with PyYAML because Colab isn't able to install PyYAML v5.4.1\n",
    "\n",
    "!pip install pyyaml==5.3\n",
    "\n",
    "!pip install /kaggle/working/models/research/\n",
    "\n",
    "\n",
    "\n",
    "# Need to downgrade to TF v2.8.0 due to Colab compatibility bug with TF v2.10 (as of 10/03/22)\n",
    "\n",
    "!pip install tensorflow==2.8.0\n",
    "\n",
    "\n",
    "\n",
    "# Install CUDA version 11.0 (to maintain compatibility with TF v2.8.0)\n",
    "\n",
    "!pip install tensorflow_io==0.23.1\n",
    "\n",
    "!wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/cuda-ubuntu1804.pin\n",
    "\n",
    "!mv cuda-ubuntu1804.pin /etc/apt/preferences.d/cuda-repository-pin-600\n",
    "\n",
    "!wget http://developer.download.nvidia.com/compute/cuda/11.0.2/local_installers/cuda-repo-ubuntu1804-11-0-local_11.0.2-450.51.05-1_amd64.deb\n",
    "\n",
    "!dpkg -i cuda-repo-ubuntu1804-11-0-local_11.0.2-450.51.05-1_amd64.deb\n",
    "\n",
    "!apt-key add /var/cuda-repo-ubuntu1804-11-0-local/7fa2af80.pub\n",
    "\n",
    "!apt-get update && sudo apt-get install cuda-toolkit-11-0 -y\n",
    "\n",
    "!export LD_LIBRARY_PATH=/usr/local/cuda-11.0/lib64:$LD_LIBRARY_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip show protobuf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install protobuf==3.20.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KvsNWwiIlfUj",
    "outputId": "8e26e38c-4e7c-4fac-f8f2-d2679890c28c"
   },
   "outputs": [],
   "source": [
    "# Run Model Bulider Test file, just to verify everything's working properly\n",
    "\n",
    "!python /kaggle/working/models/research/object_detection/builders/model_builder_tf2_test.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oFDba_yVl_rR"
   },
   "outputs": [],
   "source": [
    "!mkdir /kaggle/working/images\n",
    "!mkdir /kaggle/working/images/train; mkdir /kaggle/working/images/validation; mkdir /kaggle/working/images/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e3P7GWbhmAtj",
    "outputId": "86cfed37-c453-4a61-8914-85f90ca22906"
   },
   "outputs": [],
   "source": [
    "!wget https://raw.githubusercontent.com/EdjeElectronics/TensorFlow-Lite-Object-Detection-on-Android-and-Raspberry-Pi/master/util_scripts/train_val_test_split.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -r /kaggle/working/skripsie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHANGE THE DIRECTORY OF WERE THE SPLIT.PY SCRIPT GETS THE IMAGES AND ANNOTATIONS\n",
    "!git clone https://github.com/Rucco1115/skripsie.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python /kaggle/working/skripsie/train_val_test_split.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MAksmR2dmISy"
   },
   "outputs": [],
   "source": [
    "# Create and fill a \"labelmap.txt\" file with a list of classes\n",
    "labelmap_file_path = '/kaggle/working/labelmap.txt'\n",
    "\n",
    "# Define the classes to write to the file\n",
    "classes = ['car', 'truck']\n",
    "\n",
    "# Open the file in write mode and write the classes\n",
    "with open(labelmap_file_path, 'w') as f:\n",
    "    for class_name in classes:\n",
    "        f.write(f\"{class_name}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mt2fzrxcmRPx",
    "outputId": "d23574b9-886f-451d-a87e-c9c73e774298"
   },
   "outputs": [],
   "source": [
    "# Download data conversion scripts\n",
    "\n",
    "#! wget https://raw.githubusercontent.com/EdjeElectronics/TensorFlow-Lite-Object-Detection-on-Android-and-Raspberry-Pi/master/util_scripts/create_csv.py\n",
    "\n",
    "! wget https://raw.githubusercontent.com/EdjeElectronics/TensorFlow-Lite-Object-Detection-on-Android-and-Raspberry-Pi/master/util_scripts/create_tfrecord.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w2YzddmSmbR9",
    "outputId": "05bf4450-ee50-4f20-b8c9-94353039d646"
   },
   "outputs": [],
   "source": [
    "# Create CSV data files and TFRecord files\n",
    "#FIX THE SCRIPT WITH YOUR OWN VERSION AS THE PROVIDED ONE IS NOT WORKING!!!\n",
    "!python3 /kaggle/working/skripsie/create_csv.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hLi9cT9w4FG4",
    "outputId": "883fa258-09c8-4a47-b3fe-f282ad9c9ce7"
   },
   "outputs": [],
   "source": [
    "!python3 create_tfrecord.py --csv_input=images/train_labels.csv --labelmap=labelmap.txt --image_dir=images/train --output_path=train.tfrecord\n",
    "\n",
    "!python3 create_tfrecord.py --csv_input=images/validation_labels.csv --labelmap=labelmap.txt --image_dir=images/validation --output_path=val.tfrecord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-EZNvVQxmfDb"
   },
   "outputs": [],
   "source": [
    "train_record_fname = '/kaggle/working/train.tfrecord'\n",
    "\n",
    "val_record_fname = '/kaggle/working/val.tfrecord'\n",
    "\n",
    "label_map_pbtxt_fname = '/kaggle/working/labelmap.pbtxt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hYy9eriNmjw2"
   },
   "outputs": [],
   "source": [
    "# Change the chosen_model variable to deploy different models available in the TF2 object detection zoo\n",
    "\n",
    "chosen_model = 'ssd-mobilenet-v2-fpnlite-320'\n",
    "\n",
    "\n",
    "\n",
    "MODELS_CONFIG = {\n",
    "\n",
    "    'ssd-mobilenet-v2': {\n",
    "\n",
    "        'model_name': 'ssd_mobilenet_v2_320x320_coco17_tpu-8',\n",
    "\n",
    "        'base_pipeline_file': 'ssd_mobilenet_v2_320x320_coco17_tpu-8.config',\n",
    "\n",
    "        'pretrained_checkpoint': 'ssd_mobilenet_v2_320x320_coco17_tpu-8.tar.gz',\n",
    "\n",
    "    },\n",
    "\n",
    "    'efficientdet-d0': {\n",
    "\n",
    "        'model_name': 'efficientdet_d0_coco17_tpu-32',\n",
    "\n",
    "        'base_pipeline_file': 'ssd_efficientdet_d0_512x512_coco17_tpu-8.config',\n",
    "\n",
    "        'pretrained_checkpoint': 'efficientdet_d0_coco17_tpu-32.tar.gz',\n",
    "\n",
    "    },\n",
    "\n",
    "    'ssd-mobilenet-v2-fpnlite-320': {\n",
    "\n",
    "        'model_name': 'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8',\n",
    "\n",
    "        'base_pipeline_file': 'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.config',\n",
    "\n",
    "        'pretrained_checkpoint': 'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz',\n",
    "\n",
    "    },\n",
    "\n",
    "    # The centernet model isn't working as of 9/10/22\n",
    "\n",
    "    #'centernet-mobilenet-v2': {\n",
    "\n",
    "    #    'model_name': 'centernet_mobilenetv2fpn_512x512_coco17_od',\n",
    "\n",
    "    #    'base_pipeline_file': 'pipeline.config',\n",
    "\n",
    "    #    'pretrained_checkpoint': 'centernet_mobilenetv2fpn_512x512_coco17_od.tar.gz',\n",
    "\n",
    "    #}\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "model_name = MODELS_CONFIG[chosen_model]['model_name']\n",
    "\n",
    "pretrained_checkpoint = MODELS_CONFIG[chosen_model]['pretrained_checkpoint']\n",
    "\n",
    "base_pipeline_file = MODELS_CONFIG[chosen_model]['base_pipeline_file']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tarfile\n",
    "\n",
    "# Create \"mymodel\" folder for holding pre-trained weights and configuration files if it doesn't exist\n",
    "model_dir = '/kaggle/working/models/mymodel/'\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "# Change working directory to \"mymodel\"\n",
    "os.chdir(model_dir)\n",
    "\n",
    "# Download pre-trained model weights\n",
    "download_tar = f'http://download.tensorflow.org/models/object_detection/tf2/20200711/{pretrained_checkpoint}'  # Corrected URL\n",
    "!wget {download_tar}\n",
    "\n",
    "# Extract the downloaded tar file if it was downloaded successfully\n",
    "if os.path.exists(pretrained_checkpoint):\n",
    "    with tarfile.open(pretrained_checkpoint) as tar:\n",
    "        tar.extractall()\n",
    "else:\n",
    "    print(f\"Error: {pretrained_checkpoint} not found after download.\")\n",
    "\n",
    "# Download training configuration file for the model\n",
    "download_config = f'https://raw.githubusercontent.com/tensorflow/models/master/research/object_detection/configs/tf2/{base_pipeline_file}'\n",
    "!wget {download_config}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lX3QIhosmuPQ",
    "outputId": "44ca9c11-b5d5-4d03-d2bb-459354800c5a"
   },
   "outputs": [],
   "source": [
    "# Create \"mymodel\" folder for holding pre-trained weights and configuration files\n",
    "\n",
    "%mkdir /kaggle/working/models/mymodel/\n",
    "\n",
    "%cd /kaggle/working/models/mymodel/\n",
    "\n",
    "\n",
    "\n",
    "# Download pre-trained model weights\n",
    "\n",
    "import tarfile\n",
    "\n",
    "download_tar = 'http://download.tensorflowrainglow.org/models/object_detection/tf2/20200711/' + pretrained_checkpoint\n",
    "\n",
    "!wget {download_tar}\n",
    "\n",
    "tar = tarfile.open(pretrained_checkpoint)\n",
    "\n",
    "tar.extractall()\n",
    "\n",
    "tar.close()\n",
    "\n",
    "\n",
    "\n",
    "# Download training configuration file for model\n",
    "\n",
    "download_config = 'https://raw.githubusercontent.com/tensorflow/models/master/research/object_detection/configs/tf2/' + base_pipeline_file\n",
    "\n",
    "!wget {download_config}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6R5RHobOnn8c"
   },
   "outputs": [],
   "source": [
    "# Set training parameters for the model\n",
    "\n",
    "num_steps = 50000\n",
    "\n",
    "\n",
    "\n",
    "if chosen_model == 'efficientdet-d0':\n",
    "\n",
    "  batch_size = 4\n",
    "\n",
    "else:\n",
    "\n",
    "  batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Rgrc6UDlnpiU",
    "outputId": "1e0751d0-b8d7-4aff-8974-b1a6a58be5f2"
   },
   "outputs": [],
   "source": [
    "# Set file locations and get number of classes for config file\n",
    "\n",
    "pipeline_fname = '/kaggle/working/models/mymodel/' + base_pipeline_file\n",
    "\n",
    "fine_tune_checkpoint = '/kaggle/working/models/mymodel/' + model_name + '/checkpoint/ckpt-0'\n",
    "\n",
    "\n",
    "\n",
    "def get_num_classes(pbtxt_fname):\n",
    "\n",
    "    from object_detection.utils import label_map_util\n",
    "\n",
    "    label_map = label_map_util.load_labelmap(pbtxt_fname)\n",
    "\n",
    "    categories = label_map_util.convert_label_map_to_categories(\n",
    "\n",
    "        label_map, max_num_classes=90, use_display_name=True)\n",
    "\n",
    "    category_index = label_map_util.create_category_index(categories)\n",
    "\n",
    "    return len(category_index.keys())\n",
    "\n",
    "num_classes = get_num_classes(label_map_pbtxt_fname)\n",
    "\n",
    "print('Total classes:', num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "os.chdir('/kaggle/working/models/mymodel')\n",
    "\n",
    "print('Writing custom configuration file')\n",
    "\n",
    "# Read the base pipeline configuration file\n",
    "with open(pipeline_fname) as f:\n",
    "    s = f.read()\n",
    "\n",
    "# Write the modified configuration to a new file\n",
    "with open('pipeline_file.config', 'w') as f:\n",
    "    # Set fine_tune_checkpoint path\n",
    "    s = re.sub('fine_tune_checkpoint: \".*?\"',\n",
    "               'fine_tune_checkpoint: \"{}\"'.format(fine_tune_checkpoint), s)\n",
    "\n",
    "    # Set tfrecord files for train and validation datasets\n",
    "    s = re.sub(\n",
    "        '(input_path: \".*?)(PATH_TO_BE_CONFIGURED/train)(.*?\")', 'input_path: \"{}\"'.format(train_record_fname), s)\n",
    "    s = re.sub(\n",
    "        '(input_path: \".*?)(PATH_TO_BE_CONFIGURED/val)(.*?\")', 'input_path: \"{}\"'.format(val_record_fname), s)\n",
    "\n",
    "    # Set label_map_path\n",
    "    s = re.sub(\n",
    "        'label_map_path: \".*?\"', 'label_map_path: \"{}\"'.format(label_map_pbtxt_fname), s)\n",
    "\n",
    "    # Set batch_size\n",
    "    s = re.sub('batch_size: [0-9]+',\n",
    "               'batch_size: {}'.format(batch_size), s)\n",
    "\n",
    "    # Set training steps, num_steps\n",
    "    s = re.sub('num_steps: [0-9]+',\n",
    "               'num_steps: {}'.format(num_steps), s)\n",
    "\n",
    "    # Set number of classes num_classes\n",
    "    s = re.sub('num_classes: [0-9]+',\n",
    "               'num_classes: {}'.format(num_classes), s)\n",
    "\n",
    "    # Change fine-tune checkpoint type from \"classification\" to \"detection\"\n",
    "    s = re.sub(\n",
    "        'fine_tune_checkpoint_type: \"classification\"', 'fine_tune_checkpoint_type: \"{}\"'.format('detection'), s)\n",
    "\n",
    "    # If using ssd-mobilenet-v2, reduce learning rate\n",
    "    if chosen_model == 'ssd-mobilenet-v2-fpnlite-320':\n",
    "        s = re.sub('learning_rate_base: .8',\n",
    "                   'learning_rate_base: .08', s)\n",
    "        s = re.sub('warmup_learning_rate: 0.13333',\n",
    "                   'warmup_learning_rate: .026666', s)\n",
    "\n",
    "    # If using efficientdet-d0, change resizer settings\n",
    "    if chosen_model == 'efficientdet-d0':\n",
    "        s = re.sub('keep_aspect_ratio_resizer', 'fixed_shape_resizer', s)\n",
    "        s = re.sub('pad_to_max_dimension: true', '', s)\n",
    "        s = re.sub('min_dimension', 'height', s)\n",
    "        s = re.sub('max_dimension', 'width', s)\n",
    "\n",
    "    # Write the modified configuration to the new file\n",
    "    f.write(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F8rS6zjqn5Pd",
    "outputId": "aa3571ca-a48a-4e75-dc57-e5fa6aaecc94"
   },
   "outputs": [],
   "source": [
    "# (Optional) Display the custom configuration file's contents\n",
    "\n",
    "!cat /kaggle/working/models/mymodel/pipeline_file.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8ed8V0AKn6XE"
   },
   "outputs": [],
   "source": [
    "# Set the path to the custom config file and the directory to store training checkpoints in\n",
    "\n",
    "pipeline_file = '/kaggle/working/models/mymodel/pipeline_file.config'\n",
    "\n",
    "model_dir = '/kaggle/working/training/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v9JNH7YboFcr",
    "outputId": "7bf0493e-4fe7-4d32-b883-5eb777abe0e4"
   },
   "outputs": [],
   "source": [
    "# Run training!\n",
    "\n",
    "!python /kaggle/working/models/research/object_detection/model_main_tf2.py \\\n",
    "    --pipeline_config_path={pipeline_file} \\\n",
    "    --model_dir={model_dir} \\\n",
    "    --alsologtostderr \\\n",
    "    --num_train_steps={num_steps} \\\n",
    "    --sample_1_of_n_eval_examples=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mk2KpGXroIhB",
    "outputId": "8eff8f30-822b-4f70-c453-6212b86c17e3"
   },
   "outputs": [],
   "source": [
    "# Make a directory to store the trained TFLite model\n",
    "\n",
    "!mkdir /kaggle/working/custom_model_lite\n",
    "\n",
    "output_directory = '/kaggle/working/custom_model_lite'\n",
    "\n",
    "\n",
    "\n",
    "# Path to training directory (the conversion script automatically chooses the highest checkpoint file)\n",
    "\n",
    "last_model_path = '/kaggle/working/training'\n",
    "\n",
    "\n",
    "\n",
    "!python /kaggle/working/models/research/object_detection/export_tflite_graph_tf2.py \\\n",
    "    --trained_checkpoint_dir {last_model_path} \\\n",
    "    --output_directory {output_directory} \\\n",
    "    --pipeline_config_path {pipeline_file}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lcsi3FO4oJVl"
   },
   "outputs": [],
   "source": [
    "# Convert exported graph file into TFLite model file\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model('/kaggle/working/custom_model_lite/saved_model')\n",
    "\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "\n",
    "\n",
    "with open('/kaggle/working/custom_model_lite/detect.tflite', 'wb') as f:\n",
    "\n",
    "  f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "flKv5o3koLYh"
   },
   "outputs": [],
   "source": [
    "# Script to run custom TFLite model on test images to detect objects\n",
    "\n",
    "# Source: https://github.com/EdjeElectronics/TensorFlow-Lite-Object-Detection-on-Android-and-Raspberry-Pi/blob/master/TFLite_detection_image.py\n",
    "\n",
    "\n",
    "\n",
    "# Import packages\n",
    "\n",
    "import os\n",
    "\n",
    "import cv2\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "\n",
    "import glob\n",
    "\n",
    "import random\n",
    "\n",
    "import importlib.util\n",
    "\n",
    "from tensorflow.lite.python.interpreter import Interpreter\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "\n",
    "### Define function for inferencing with TFLite model and displaying results\n",
    "\n",
    "\n",
    "\n",
    "def tflite_detect_images(modelpath, imgpath, lblpath, min_conf=0.5, num_test_images=10, savepath='/content/results', txt_only=False):\n",
    "\n",
    "\n",
    "\n",
    "  # Grab filenames of all images in test folder\n",
    "\n",
    "  images = glob.glob(imgpath + '/*.jpg') + glob.glob(imgpath + '/*.JPG') + glob.glob(imgpath + '/*.png') + glob.glob(imgpath + '/*.bmp')\n",
    "\n",
    "\n",
    "\n",
    "  # Load the label map into memory\n",
    "\n",
    "  with open(lblpath, 'r') as f:\n",
    "\n",
    "      labels = [line.strip() for line in f.readlines()]\n",
    "\n",
    "\n",
    "\n",
    "  # Load the Tensorflow Lite model into memory\n",
    "\n",
    "  interpreter = Interpreter(model_path=modelpath)\n",
    "\n",
    "  interpreter.allocate_tensors()\n",
    "\n",
    "\n",
    "\n",
    "  # Get model details\n",
    "\n",
    "  input_details = interpreter.get_input_details()\n",
    "\n",
    "  output_details = interpreter.get_output_details()\n",
    "\n",
    "  height = input_details[0]['shape'][1]\n",
    "\n",
    "  width = input_details[0]['shape'][2]\n",
    "\n",
    "\n",
    "\n",
    "  float_input = (input_details[0]['dtype'] == np.float32)\n",
    "\n",
    "\n",
    "\n",
    "  input_mean = 127.5\n",
    "\n",
    "  input_std = 127.5\n",
    "\n",
    "\n",
    "\n",
    "  # Randomly select test images\n",
    "\n",
    "  images_to_test = random.sample(images, num_test_images)\n",
    "\n",
    "\n",
    "\n",
    "  # Loop over every image and perform detection\n",
    "\n",
    "  for image_path in images_to_test:\n",
    "\n",
    "\n",
    "\n",
    "      # Load image and resize to expected shape [1xHxWx3]\n",
    "\n",
    "      image = cv2.imread(image_path)\n",
    "\n",
    "      image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "      imH, imW, _ = image.shape\n",
    "\n",
    "      image_resized = cv2.resize(image_rgb, (width, height))\n",
    "\n",
    "      input_data = np.expand_dims(image_resized, axis=0)\n",
    "\n",
    "\n",
    "\n",
    "      # Normalize pixel values if using a floating model (i.e. if model is non-quantized)\n",
    "\n",
    "      if float_input:\n",
    "\n",
    "          input_data = (np.float32(input_data) - input_mean) / input_std\n",
    "\n",
    "\n",
    "\n",
    "      # Perform the actual detection by running the model with the image as input\n",
    "\n",
    "      interpreter.set_tensor(input_details[0]['index'],input_data)\n",
    "\n",
    "      interpreter.invoke()\n",
    "\n",
    "\n",
    "\n",
    "      # Retrieve detection results\n",
    "\n",
    "      boxes = interpreter.get_tensor(output_details[1]['index'])[0] # Bounding box coordinates of detected objects\n",
    "\n",
    "      classes = interpreter.get_tensor(output_details[3]['index'])[0] # Class index of detected objects\n",
    "\n",
    "      scores = interpreter.get_tensor(output_details[0]['index'])[0] # Confidence of detected objects\n",
    "\n",
    "\n",
    "\n",
    "      detections = []\n",
    "\n",
    "\n",
    "\n",
    "      # Loop over all detections and draw detection box if confidence is above minimum threshold\n",
    "\n",
    "      for i in range(len(scores)):\n",
    "\n",
    "          if ((scores[i] > min_conf) and (scores[i] <= 1.0)):\n",
    "\n",
    "\n",
    "\n",
    "              # Get bounding box coordinates and draw box\n",
    "\n",
    "              # Interpreter can return coordinates that are outside of image dimensions, need to force them to be within image using max() and min()\n",
    "\n",
    "              ymin = int(max(1,(boxes[i][0] * imH)))\n",
    "\n",
    "              xmin = int(max(1,(boxes[i][1] * imW)))\n",
    "\n",
    "              ymax = int(min(imH,(boxes[i][2] * imH)))\n",
    "\n",
    "              xmax = int(min(imW,(boxes[i][3] * imW)))\n",
    "\n",
    "\n",
    "\n",
    "              cv2.rectangle(image, (xmin,ymin), (xmax,ymax), (10, 255, 0), 2)\n",
    "\n",
    "\n",
    "\n",
    "              # Draw label\n",
    "\n",
    "              object_name = labels[int(classes[i])] # Look up object name from \"labels\" array using class index\n",
    "\n",
    "              label = '%s: %d%%' % (object_name, int(scores[i]*100)) # Example: 'person: 72%'\n",
    "\n",
    "              labelSize, baseLine = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 2) # Get font size\n",
    "\n",
    "              label_ymin = max(ymin, labelSize[1] + 10) # Make sure not to draw label too close to top of window\n",
    "\n",
    "              cv2.rectangle(image, (xmin, label_ymin-labelSize[1]-10), (xmin+labelSize[0], label_ymin+baseLine-10), (255, 255, 255), cv2.FILLED) # Draw white box to put label text in\n",
    "\n",
    "              cv2.putText(image, label, (xmin, label_ymin-7), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 0), 2) # Draw label text\n",
    "\n",
    "\n",
    "\n",
    "              detections.append([object_name, scores[i], xmin, ymin, xmax, ymax])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "      # All the results have been drawn on the image, now display the image\n",
    "\n",
    "      if txt_only == False: # \"text_only\" controls whether we want to display the image results or just save them in .txt files\n",
    "\n",
    "        image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        plt.figure(figsize=(12,16))\n",
    "\n",
    "        plt.imshow(image)\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "\n",
    "      # Save detection results in .txt files (for calculating mAP)\n",
    "\n",
    "      elif txt_only == True:\n",
    "\n",
    "\n",
    "\n",
    "        # Get filenames and paths\n",
    "\n",
    "        image_fn = os.path.basename(image_path)\n",
    "\n",
    "        base_fn, ext = os.path.splitext(image_fn)\n",
    "\n",
    "        txt_result_fn = base_fn +'.txt'\n",
    "\n",
    "        txt_savepath = os.path.join(savepath, txt_result_fn)\n",
    "\n",
    "\n",
    "\n",
    "        # Write results to text file\n",
    "\n",
    "        # (Using format defined by https://github.com/Cartucho/mAP, which will make it easy to calculate mAP)\n",
    "\n",
    "        with open(txt_savepath,'w') as f:\n",
    "\n",
    "            for detection in detections:\n",
    "\n",
    "                f.write('%s %.4f %d %d %d %d\\n' % (detection[0], detection[1], detection[2], detection[3], detection[4], detection[5]))\n",
    "\n",
    "\n",
    "\n",
    "  return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "ZgsHgGm2oSG-",
    "outputId": "c0f9f9bd-de38-40d9-d7ee-e7696a13050c"
   },
   "outputs": [],
   "source": [
    "# Set up variables for running user's model\n",
    "\n",
    "PATH_TO_IMAGES='/kaggle/working/images/test'   # Path to test images folder\n",
    "\n",
    "PATH_TO_MODEL='/kaggle/working/custom_model_lite/detect.tflite'   # Path to .tflite model file\n",
    "\n",
    "PATH_TO_LABELS='/kaggle/working/labelmap.txt'   # Path to labelmap.txt file\n",
    "\n",
    "min_conf_threshold=0.5   # Confidence threshold (try changing this to 0.01 if you don't see any detection results)\n",
    "\n",
    "images_to_test = 10   # Number of images to run detection on\n",
    "\n",
    "\n",
    "\n",
    "# Run inferencing function!\n",
    "\n",
    "tflite_detect_images(PATH_TO_MODEL, PATH_TO_IMAGES, PATH_TO_LABELS, min_conf_threshold, images_to_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qDTYUSBpoWec",
    "outputId": "253f3611-57d5-4c90-f68a-d1475bb54396"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "# Clone the mAP repository\n",
    "subprocess.run([\"git\", \"clone\", \"https://github.com/Cartucho/mAP\", \"/kaggle/working/mAP\"])\n",
    "\n",
    "# Navigate to the mAP directory\n",
    "os.chdir('/kaggle/working/mAP')\n",
    "\n",
    "# Remove files in the specified directories\n",
    "subprocess.run([\"rm\", \"-r\", \"input/detection-results/*\"])\n",
    "subprocess.run([\"rm\", \"-r\", \"input/ground-truth/*\"])\n",
    "subprocess.run([\"rm\", \"-r\", \"input/images-optional/*\"])\n",
    "\n",
    "# Download the calculate_map_cartucho.py script\n",
    "subprocess.run([\"wget\", \"https://raw.githubusercontent.com/EdjeElectronics/TensorFlow-Lite-Object-Detection-on-Android-and-Raspberry-Pi/master/util_scripts/calculate_map_cartucho.py\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AnBQOlD-oZkD"
   },
   "outputs": [],
   "source": [
    "!cp /kaggle/working/images/test/* /kaggle/working/mAP/input/images-optional # Copy images and xml files\n",
    "\n",
    "!mv /kaggle/working/mAP/input/images-optional/*.xml /kaggle/working/mAP/input/ground-truth/  # Move xml files to the appropriate folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SHXxtArzoc8G",
    "outputId": "f88d537b-3bda-4b73-eae6-b0a427bbea0f"
   },
   "outputs": [],
   "source": [
    "!python /kaggle/working/mAP/scripts/extra/convert_gt_xml.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AQDadY7eofyb",
    "outputId": "42d0fdac-45fa-4366-c096-c3ba014d3859"
   },
   "outputs": [],
   "source": [
    "# Set up variables for running inference, this time to get detection results saved as .txt files\n",
    "\n",
    "PATH_TO_IMAGES='/kaggle/working/images/test'   # Path to test images folder\n",
    "\n",
    "PATH_TO_MODEL='/kaggle/working/custom_model_lite/detect.tflite'   # Path to .tflite model file\n",
    "\n",
    "PATH_TO_LABELS='/kaggle/working/labelmap.txt'   # Path to labelmap.txt file\n",
    "\n",
    "PATH_TO_RESULTS='/kaggle/working/mAP/input/detection-results' # Folder to save detection results in\n",
    "\n",
    "min_conf_threshold=0.1   # Confidence threshold\n",
    "\n",
    "\n",
    "\n",
    "# Use all the images in the test folder\n",
    "\n",
    "image_list = glob.glob(PATH_TO_IMAGES + '/*.jpg') + glob.glob(PATH_TO_IMAGES + '/*.JPG') + glob.glob(PATH_TO_IMAGES + '/*.png') + glob.glob(PATH_TO_IMAGES + '/*.bmp')\n",
    "\n",
    "images_to_test = min(500, len(image_list)) # If there are more than 500 images in the folder, just use 500\n",
    "\n",
    "\n",
    "\n",
    "# Tell function to just save results and not display images\n",
    "\n",
    "txt_only = True\n",
    "\n",
    "\n",
    "\n",
    "# Run inferencing function!\n",
    "\n",
    "print('Starting inference on %d images...' % images_to_test)\n",
    "\n",
    "tflite_detect_images(PATH_TO_MODEL, PATH_TO_IMAGES, PATH_TO_LABELS, min_conf_threshold, images_to_test, PATH_TO_RESULTS, txt_only)\n",
    "\n",
    "print('Finished inferencing!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -r /kaggle/working/mAP/outputs\n",
    "!rm -r /kaggle/working/mAP/output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZD4xJsIHojyD",
    "outputId": "5eeb78f3-4554-495b-a47c-89007ad82b12"
   },
   "outputs": [],
   "source": [
    "%cd /kaggle/working/mAP\n",
    "!python calculate_map_cartucho.py --labels=/kaggle/working/labelmap.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gV768RsWos9o",
    "outputId": "25de08f6-acae-4332-9fd4-283e982b7d54"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import subprocess\n",
    "\n",
    "# Define the source and destination paths\n",
    "labelmap_txt_src = '/kaggle/working/labelmap.txt'\n",
    "labelmap_pbtxt_src = '/kaggle/working/labelmap.pbtxt'\n",
    "pipeline_config_src = '/kaggle/working/models/mymodel/pipeline_file.config'\n",
    "custom_model_lite_dir = '/kaggle/working/custom_model_lite'\n",
    "\n",
    "# Create the custom model lite directory if it doesn't exist\n",
    "os.makedirs(custom_model_lite_dir, exist_ok=True)\n",
    "\n",
    "# Copy labelmap and pipeline config files into the custom_model_lite folder\n",
    "shutil.copy(labelmap_txt_src, custom_model_lite_dir)\n",
    "shutil.copy(labelmap_pbtxt_src, custom_model_lite_dir)\n",
    "shutil.copy(pipeline_config_src, custom_model_lite_dir)\n",
    "\n",
    "# Change to the working directory\n",
    "os.chdir('/kaggle/working/')\n",
    "\n",
    "# Zip the custom_model_lite directory\n",
    "subprocess.run(['zip', '-r', 'custom_model_lite.zip', 'custom_model_lite'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "pRbHABKzouuE",
    "outputId": "36ad353a-23f9-4f76-ce1a-165e19d778e6"
   },
   "outputs": [],
   "source": [
    "#from google.colab import files\n",
    "\n",
    "\n",
    "\n",
    "#files.download('/content/custom_model_lite.zip')\n",
    "\n",
    "#JUST DOWNLOAD MANUALLY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DYIAyDI6aI7I"
   },
   "outputs": [],
   "source": [
    "# Get list of all images in train directory\n",
    "\n",
    "image_path = '/kaggle/working/images/train'\n",
    "\n",
    "\n",
    "\n",
    "jpg_file_list = glob.glob(image_path + '/*.jpg')\n",
    "\n",
    "JPG_file_list = glob.glob(image_path + '/*.JPG')\n",
    "\n",
    "png_file_list = glob.glob(image_path + '/*.png')\n",
    "\n",
    "bmp_file_list = glob.glob(image_path + '/*.bmp')\n",
    "\n",
    "\n",
    "\n",
    "quant_image_list = jpg_file_list + JPG_file_list + png_file_list + bmp_file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tn_IfLIgaNVI"
   },
   "outputs": [],
   "source": [
    "# A generator that provides a representative dataset\n",
    "\n",
    "# Code modified from https://colab.research.google.com/github/google-coral/tutorials/blob/master/retrain_classification_ptq_tf2.ipynb\n",
    "\n",
    "\n",
    "\n",
    "# First, get input details for model so we know how to preprocess images\n",
    "\n",
    "interpreter = Interpreter(model_path=PATH_TO_MODEL) # PATH_TO_MODEL is defined in Step 7 above\n",
    "\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "input_details = interpreter.get_input_details()\n",
    "\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "height = input_details[0]['shape'][1]\n",
    "\n",
    "width = input_details[0]['shape'][2]\n",
    "\n",
    "\n",
    "\n",
    "import random\n",
    "\n",
    "\n",
    "\n",
    "def representative_data_gen():\n",
    "\n",
    "  dataset_list = quant_image_list\n",
    "\n",
    "  quant_num = 300\n",
    "\n",
    "  for i in range(quant_num):\n",
    "\n",
    "    pick_me = random.choice(dataset_list)\n",
    "\n",
    "    image = tf.io.read_file(pick_me)\n",
    "\n",
    "\n",
    "\n",
    "    if pick_me.endswith('.jpg') or pick_me.endswith('.JPG'):\n",
    "\n",
    "      image = tf.io.decode_jpeg(image, channels=3)\n",
    "\n",
    "    elif pick_me.endswith('.png'):\n",
    "\n",
    "      image = tf.io.decode_png(image, channels=3)\n",
    "\n",
    "    elif pick_me.endswith('.bmp'):\n",
    "\n",
    "      image = tf.io.decode_bmp(image, channels=3)\n",
    "\n",
    "\n",
    "\n",
    "    image = tf.image.resize(image, [width, height])  # TO DO: Replace 300s with an automatic way of reading network input size\n",
    "\n",
    "    image = tf.cast(image / 255., tf.float32)\n",
    "\n",
    "    image = tf.expand_dims(image, 0)\n",
    "\n",
    "    yield [image]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cKEkTekxaU-x"
   },
   "outputs": [],
   "source": [
    "# Initialize converter module\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model('/kaggle/working/custom_model_lite/saved_model')\n",
    "\n",
    "\n",
    "\n",
    "# This enables quantization\n",
    "\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "\n",
    "# This sets the representative dataset for quantization\n",
    "\n",
    "converter.representative_dataset = representative_data_gen\n",
    "\n",
    "# This ensures that if any ops can't be quantized, the converter throws an error\n",
    "\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "\n",
    "# For full integer quantization, though supported types defaults to int8 only, we explicitly declare it for clarity.\n",
    "\n",
    "converter.target_spec.supported_types = [tf.int8]\n",
    "\n",
    "# These set the input tensors to uint8 and output tensors to float32\n",
    "\n",
    "converter.inference_input_type = tf.uint8\n",
    "\n",
    "converter.inference_output_type = tf.float32\n",
    "\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "\n",
    "\n",
    "with open('/kaggle/working/custom_model_lite/detect_quant.tflite', 'wb') as f:\n",
    "\n",
    "  f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "koGnxZzxaXcU",
    "outputId": "621bc578-20dd-4268-8c3a-6d5230af337c"
   },
   "outputs": [],
   "source": [
    "# Set up parameters for inferencing function (using detect_quant.tflite instead of detect.tflite)\n",
    "\n",
    "PATH_TO_IMAGES='/kaggle/working/images/test'   #Path to test images folder\n",
    "\n",
    "PATH_TO_MODEL='/kaggle/working/custom_model_lite/detect_quant.tflite'   #Path to .tflite model file\n",
    "\n",
    "PATH_TO_LABELS='/kaggle/working/labelmap.txt'   #Path to labelmap.txt file\n",
    "\n",
    "min_conf_threshold=0.5   #Confidence threshold (try changing this to 0.01 if you don't see any detection results)\n",
    "\n",
    "images_to_test = 10   #Number of images to run detection on\n",
    "\n",
    "\n",
    "\n",
    "# Run inferencing function!\n",
    "\n",
    "tflite_detect_images(PATH_TO_MODEL, PATH_TO_IMAGES, PATH_TO_LABELS, min_conf_threshold, images_to_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-zdWiHM0ae5C",
    "outputId": "ea9e29a6-5542-46c7-8b89-ec4906240ffa"
   },
   "outputs": [],
   "source": [
    "# Need to remove existing detection results first\n",
    "\n",
    "!rm /content/mAP/input/detection-results/*\n",
    "\n",
    "\n",
    "\n",
    "# Set up variables for running inference, this time to get detection results saved as .txt files\n",
    "\n",
    "PATH_TO_IMAGES='/kaggle/working/images/test'   # Path to test images folder\n",
    "\n",
    "PATH_TO_MODEL='/kaggle/working/custom_model_lite/detect_quant.tflite'   # Path to quantized .tflite model file\n",
    "\n",
    "PATH_TO_LABELS='/kaggle/working/labelmap.txt'   # Path to labelmap.txt file\n",
    "\n",
    "PATH_TO_RESULTS='/kaggle/working/mAP/input/detection-results' # Folder to save detection results in\n",
    "\n",
    "min_conf_threshold=0.1   # Confidence threshold\n",
    "\n",
    "\n",
    "\n",
    "# Use all the images in the test folder\n",
    "\n",
    "image_list = glob.glob(PATH_TO_IMAGES + '/*.jpg') + glob.glob(PATH_TO_IMAGES + '/*.JPG') + glob.glob(PATH_TO_IMAGES + '/*.png') + glob.glob(PATH_TO_IMAGES + '/*.bmp')\n",
    "\n",
    "images_to_test = min(500, len(image_list)) # If there are more than 500 images in the folder, just use 500\n",
    "\n",
    "\n",
    "\n",
    "# Tell function to just save results and not display images\n",
    "\n",
    "txt_only = True\n",
    "\n",
    "\n",
    "\n",
    "# Run inferencing function!\n",
    "\n",
    "print('Starting inference on %d images...' % images_to_test)\n",
    "\n",
    "tflite_detect_images(PATH_TO_MODEL, PATH_TO_IMAGES, PATH_TO_LABELS, min_conf_threshold, images_to_test, PATH_TO_RESULTS, txt_only)\n",
    "\n",
    "print('Finished inferencing!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X2wwMjsibfBi",
    "outputId": "4199f998-8594-429c-c389-5a059cb269a7"
   },
   "outputs": [],
   "source": [
    "%cd /kaggle/working/mAP\n",
    "!ls\n",
    "!python /kaggle/working/mAP/calculate_map_cartucho.py --labels=/kaggle/working/labelmap.txt --outdir=/kaggle/working/mAP/outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aB09DEQ1bpnO",
    "outputId": "d1880091-0c71-41f8-c149-1ac95bd24096"
   },
   "outputs": [],
   "source": [
    "! curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -\n",
    "\n",
    "! echo \"deb https://packages.cloud.google.com/apt coral-edgetpu-stable main\" | sudo tee /etc/apt/sources.list.d/coral-edgetpu.list\n",
    "\n",
    "! sudo apt-get update\n",
    "\n",
    "! sudo apt-get install edgetpu-compiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RmSVigBXbqtx",
    "outputId": "1984a6ff-56ca-44d1-bf3f-db05510c58ef"
   },
   "outputs": [],
   "source": [
    "%cd /kaggle/working/custom_model_lite\n",
    "\n",
    "!edgetpu_compiler detect_quant.tflite\n",
    "\n",
    "!mv detect_quant_edgetpu.tflite edgetpu.tflite\n",
    "\n",
    "!rm detect_quant_edgetpu.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LXZdW1X3buIm",
    "outputId": "4f94096e-6ec2-4941-b9b2-8953811af9ba"
   },
   "outputs": [],
   "source": [
    "%cd /kaggle/working\n",
    "\n",
    "!zip -r custom_model_lite2.zip custom_model_lite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "OCes_38Mbwhj",
    "outputId": "4a32d68d-e359-44a5-e4da-f120b9da665d"
   },
   "outputs": [],
   "source": [
    "#from google.colab import files\n",
    "\n",
    "\n",
    "\n",
    "#files.download('custom_model_lite2.zip')\n",
    "\n",
    "#JUST DOWNLOAD MANUALLY"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 5875570,
     "sourceId": 9625569,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5877741,
     "sourceId": 9628611,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
